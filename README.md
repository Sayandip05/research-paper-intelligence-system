# ğŸ”¬ Research Paper Intelligence System

A production-ready **RAG (Retrieval-Augmented Generation)** system for intelligent research paper analysis using **LlamaIndex**, **Qdrant**, and **Multi-Agent Workflows**.

## ğŸ¯ Project Overview

This system ingests PDF research papers, chunks them with section awareness, generates embeddings, and enables intelligent Q&A with proper citations. It features a **3-agent workflow** with intent classification, section-filtered retrieval, and human-in-the-loop controls.

```mermaid
flowchart LR
    A[PDFs<br/>corpus/] -->|Section-Aware<br/>Parser| B(Section-Based<br/>Chunking)
    B -->|Canonical<br/>Labels| C{Vector Embeddings<br/>768 dimensions}
    C -->|HuggingFace<br/>BGE-base-en-v1.5| D[Qdrant<br/>Vector DB]
    D -->|Intent-Filtered<br/>Search| E[Multi-Agent<br/>Workflow]
    E -->|HITL Gate| F[Intelligent Response]
```

## âœ… Current Progress

### Week 1: Core Infrastructure âœ…
| Component | Technology | Status |
|-----------|------------|--------|
| **PDF Parsing** | LlamaIndex `SimpleDirectoryReader` | âœ… Done |
| **Chunking** | LlamaIndex `SentenceSplitter` | âœ… Done |
| **Embeddings** | `BAAI/bge-base-en-v1.5` (768 dim) | âœ… Done |
| **Vector DB** | Qdrant | âœ… Done |
| **API Framework** | FastAPI | âœ… Done |

### Week 2: Intelligent Query Engine âœ…
| Component | Technology | Status |
|-----------|------------|--------|
| **LLM Integration** | Groq (`openai/gpt-oss-120b`) | âœ… Done |
| **Query Engine** | LlamaIndex `VectorStoreIndex` | âœ… Done |
| **RAG Pipeline** | Retrieval + Generation | âœ… Done |
| **Query API** | `/api/query` endpoint | âœ… Done |

### Week 3: Multi-Agent Workflow âœ…
| Component | Technology | Status |
|-----------|------------|--------|
| **Section-Aware Parser** | `SectionAwarePDFParser` | âœ… Done |
| **Canonical Section Taxonomy** | 13 normalized section types | âœ… Done |
| **Intent Classifier** | Rule-based, priority-ordered | âœ… Done |
| **Section-Filtered Retrieval** | Qdrant metadata filters | âœ… Done |
| **HITL Gate** | Human-in-the-loop controls | âœ… Done |
| **Verbosity Control** | Brief/concise summary mode | âœ… Done |
| **Streamlit Frontend** | Temporary demo UI | âœ… Done |
| **3-Agent Workflow** | Query â†’ Retrieval â†’ Analysis | âœ… Done |

### Week 4: Guardrails AI âœ…
| Component | Technology | Status |
|-----------|------------|--------|
| **RAIL Schema** | Guardrails AI RAIL format | âœ… Done |
| **Pydantic Validation** | `ValidatedAnswer` model | âœ… Done |
| **Citation Grounding** | Rule-based verification | âœ… Done |
| **Hallucination Detection** | Heuristic-based checks | âœ… Done |
| **Auto-Retry** | Schema validation retry (max 1) | âœ… Done |
| **HITL Escalation** | Guardrails â†’ HITL pipeline | âœ… Done |

### Week 5: Current State âœ…
**Fully Operational Production-Grade RAG System**
- ï¿½ All core features implemented
- ğŸ›¡ï¸ Guardrails AI validation active
- ğŸ“Š Multi-agent workflow operational
- ğŸ” Section-aware retrieval working
- ğŸ’¬ Streamlit demo UI available

## ï¿½ğŸ—ï¸ Architecture

### Multi-Agent Workflow with Guardrails
```
User Question
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Query Orchestrator    â”‚  â†’ Intent Classification
â”‚  Agent                 â”‚  â†’ Section Targeting
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Evidence Retrieval    â”‚  â†’ Metadata-Filtered Search
â”‚  Agent                 â”‚  â†’ Qdrant Vector Query
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  HITL Gate             â”‚  â†’ Confidence Check
â”‚  (Deterministic)       â”‚  â†’ Low Evidence â†’ BLOCK
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Analysis & Synthesis  â”‚  â†’ LLM Reasoning
â”‚  Agent                 â”‚  â†’ Cited Answer
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Guardrails AI         â”‚  â†’ Schema Validation
â”‚  Validation Layer      â”‚  â†’ Citation Grounding
â”‚                        â”‚  â†’ Hallucination Detection
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â€¢ If Valid â†’ Stop Event (Answer)
â€¢ If Invalid â†’ HITL Event (Review Required)
```

### Intent Classification System
| Intent | Allowed Sections | Priority |
|--------|------------------|----------|
| `citation` | References | 100 |
| `limitations` | Discussion, Limitations | 90 |
| `future_work` | Future Work | 85 |
| `research_gaps` | Discussion, Limitations, Future Work | 80 |
| `methodology` | Methods | 70 |
| `experiments` | Experiments, Results | 60 |
| `results` | Results | 50 |
| `comparison` | Results, Experiments | 40 |
| `summary` | Abstract, Introduction | 20 |
| `general` | Abstract, Introduction, Methods, Results | 10 |

### Canonical Section Taxonomy
Only these 13 section labels are stored in the vector database:
```
Abstract, Introduction, Related Work, Methods, Experiments,
Results, Discussion, Limitations, Future Work, Conclusion,
References, Appendix, Unknown
```

### HITL Gate Trigger Conditions
Human review is required if ANY of:
- `retrieved_chunks_count < 2`
- `intent_confidence < 0.6`
- `top_similarity_score < 0.5`

## ğŸ› ï¸ Tech Stack

| Layer | Technology | Purpose |
|-------|------------|---------|
| **Framework** | LlamaIndex | RAG orchestration |
| **LLM** | Groq (openai/gpt-oss-120b) | Response generation |
| **Embeddings** | BAAI/bge-base-en-v1.5 | Text â†’ 768-dim vectors |
| **Vector DB** | Qdrant | Similarity search with filters |
| **PDF Reader** | LlamaIndex + PyMuPDF | Document ingestion |
| **API** | FastAPI | REST endpoints |
| **Frontend** | Streamlit (temporary) | Demo UI |
| **Workflow** | LlamaIndex Workflow | Event-driven agents |

## ğŸ“ Project Structure

```
research-paper-intelligence-system/
â”œâ”€â”€ corpus/                         # Put your PDFs here
â”‚   â”œâ”€â”€ paper1.pdf
â”‚   â””â”€â”€ paper2.pdf
â”œâ”€â”€ backend/
â”‚   â””â”€â”€ app/
â”‚       â”œâ”€â”€ api/routes/
â”‚       â”‚   â”œâ”€â”€ search.py           # Vector search endpoints
â”‚       â”‚   â”œâ”€â”€ query.py            # Intelligent query endpoints
â”‚       â”‚   â””â”€â”€ workflow_query.py   # Workflow-based query
â”‚       â”œâ”€â”€ agents/
â”‚       â”‚   â”œâ”€â”€ query_orchestrator.py   # Agent 1: Intent & routing
â”‚       â”‚   â”œâ”€â”€ evidence_retrieval.py   # Agent 2: Section-filtered search
â”‚       â”‚   â””â”€â”€ analysis_synthesis.py   # Agent 3: LLM reasoning
â”‚       â”œâ”€â”€ db/
â”‚       â”‚   â””â”€â”€ qdrant_client.py    # Qdrant with metadata filters
â”‚       â”œâ”€â”€ models/
â”‚       â”‚   â”œâ”€â”€ paper.py            # Paper data models
â”‚       â”‚   â”œâ”€â”€ chunk.py            # Chunk data models
â”‚       â”‚   â”œâ”€â”€ query.py            # Query request/response
â”‚       â”‚   â””â”€â”€ events.py           # Workflow events
â”‚       â”œâ”€â”€ services/
â”‚       â”‚   â”œâ”€â”€ pdf_parser.py       # SectionAwarePDFParser
â”‚       â”‚   â”œâ”€â”€ chunking.py         # Section-aware chunking
â”‚       â”‚   â”œâ”€â”€ embeddings.py       # HuggingFace embeddings
â”‚       â”‚   â”œâ”€â”€ llm_service.py      # Groq LLM integration
â”‚       â”‚   â”œâ”€â”€ intent_classifier.py # Rule-based intent detection
â”‚       â”‚   â”œâ”€â”€ hitl_gate.py        # Human-in-the-loop controls
â”‚       â”‚   â””â”€â”€ query_engine.py     # Intelligent Query Engine
â”‚       â”œâ”€â”€ workflows/
â”‚       â”‚   â””â”€â”€ research_workflow.py # LlamaIndex Workflow
â”‚       â”œâ”€â”€ config.py               # Settings & configuration
â”‚       â””â”€â”€ main.py                 # FastAPI app
â”œâ”€â”€ frontend/
â”‚   â””â”€â”€ app.py                      # Streamlit UI (temporary)
â”œâ”€â”€ build_corpus.py                 # Main ingestion script
â”œâ”€â”€ interactive_query.py            # CLI Q&A interface
â”œâ”€â”€ docker-compose.yml              # Qdrant container
â”œâ”€â”€ requirements.txt                # Python dependencies
â”œâ”€â”€ .env                            # Environment variables
â””â”€â”€ README.md
```

## ğŸš€ Quick Start

### 1. Prerequisites
- Python 3.10+
- Docker (for Qdrant)
- Groq API key (free at https://console.groq.com)

### 2. Setup

```bash
# Clone and navigate
cd research-paper-intelligence-system

# Create virtual environment
python -m venv venv_clean
.\venv_clean\Scripts\activate  # Windows
# source venv_clean/bin/activate  # Linux/Mac

# Install dependencies
pip install -r requirements.txt
```

### 3. Environment Variables

Create `.env` file:
```env
GROQ_API_KEY=your_groq_api_key_here
```

### 4. Start Qdrant

```bash
docker-compose up -d
```

### 5. Add PDFs & Build Corpus

```bash
# Place PDFs in corpus/ folder
# Then build the vector database
python build_corpus.py
```

### 6. Run the System

**Option A: Interactive CLI**
```bash
python interactive_query.py
```

**Option B: FastAPI + Streamlit**
```bash
# Terminal 1: Start backend
cd backend
uvicorn app.main:app --reload

# Terminal 2: Start frontend
streamlit run frontend/app.py
```

Visit:
- API Docs: http://localhost:8000/docs
- Streamlit UI: http://localhost:8501

## ğŸ’¡ Example Queries

| Query | Intent | Sections Searched |
|-------|--------|-------------------|
| "What is LoRA?" | `summary` | Abstract, Introduction |
| "How does QLoRA work?" | `methodology` | Methods |
| "What are the limitations?" | `limitations` | Discussion, Limitations |
| "Compare LoRA and full fine-tuning" | `comparison` | Results, Experiments |
| "Give a brief summary" | `summary` (brief mode) | Abstract, Introduction |

## âš™ï¸ Configuration

Edit `backend/app/config.py`:

```python
# Embedding Model
embedding_model: str = "BAAI/bge-base-en-v1.5"
embedding_dim: int = 768

# Chunking
chunk_size: int = 1000
chunk_overlap: int = 200

# Qdrant
qdrant_host: str = "localhost"
qdrant_port: int = 6333
qdrant_collection_name: str = "research_papers"

# LLM
llm_model: str = "openai/gpt-oss-120b"
```

## ğŸ”¬ Key Features

### Section-Aware Chunking
- Detects real section headers (Abstract, Methods, Results, etc.)
- Normalizes to 13 canonical section names
- Rejects noise (tables, figures, OCR artifacts)

### Intent-Based Retrieval
- Rule-based intent classifier (no ML/LLM)
- Priority-ordered conflict resolution
- Metadata-filtered vector search

### Human-in-the-Loop Controls
- Blocks low-confidence answers
- Returns structured review requests
- Deterministic trigger conditions

### Verbosity Control
- Detects "brief/short/small" hints
- Produces concise bullet-point answers
- No LLM reasoning for verbosity

### Guardrails AI Validation
- **Pydantic Schema Enforcement**: Strict JSON output with `ValidatedAnswer` model
- **Citation Grounding**: Verifies all citations exist in retrieved chunks
- **Hallucination Detection**: Heuristic-based pattern matching
- **Auto-Retry**: Automatically re-asks LLM once if validation fails
- **HITL Escalation**: Triggers human review when quality is insufficient

## ğŸ—ºï¸ Roadmap

- [x] **Week 1**: PDF â†’ Chunks â†’ Embeddings â†’ Qdrant
- [x] **Week 2**: RAG Query Engine with LlamaIndex + Groq LLM
- [x] **Week 3**: Multi-Agent Workflow + HITL + Section Filtering
- [x] **Week 4**: Guardrails AI + Schema Validation
- [x] **Week 5**: Production-Grade RAG System (Current)
- [ ] **Week 6**: Cloud Deployment + Monitoring

## ğŸ“ License

MIT License

---

Built with â¤ï¸ using LlamaIndex, Qdrant, Groq, and Streamlit
