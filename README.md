# ğŸ”¬ Research Paper Intelligence System

A production-ready **RAG (Retrieval-Augmented Generation)** system for intelligent research paper analysis using **LlamaIndex**, **Qdrant**, and **Multi-Agent Workflows**.

## ğŸ¯ Project Overview

This system ingests PDF research papers, chunks them with section awareness, generates embeddings, and enables intelligent Q&A with proper citations. It features a **3-agent workflow** with intent classification, section-filtered retrieval, and human-in-the-loop controls.

```mermaid
flowchart LR
    A[PDFs<br/>corpus/] -->|Section-Aware<br/>Parser| B(Section-Based<br/>Chunking)
    B -->|Canonical<br/>Labels| C{Hybrid Embeddings}
    C -->|Dense: BGE| D1[Dense Vectors<br/>768-dim]
    C -->|Sparse: BM42| D2[Sparse Vectors<br/>fastembed]
    D1 --> D[Qdrant<br/>Vector DB]
    D2 --> D
    D -->|RRF Fusion<br/>Hybrid Search| E[Multi-Agent<br/>Workflow]
    E -->|HITL Gate| F[Intelligent Response]
```

## âœ… Current Progress

### Week 1: Core Infrastructure âœ…
| Component | Technology | Status |
|-----------|------------|--------|
| **PDF Parsing** | LlamaIndex `SimpleDirectoryReader` | âœ… Done |
| **Chunking** | LlamaIndex `SentenceSplitter` | âœ… Done |
| **Embeddings** | `BAAI/bge-base-en-v1.5` (768 dim) | âœ… Done |
| **Vector DB** | Qdrant | âœ… Done |
| **API Framework** | FastAPI | âœ… Done |

### Week 2: Intelligent Query Engine âœ…
| Component | Technology | Status |
|-----------|------------|--------|
| **LLM Integration** | Groq (`openai/gpt-oss-120b`) | âœ… Done |
| **Query Engine** | LlamaIndex `VectorStoreIndex` | âœ… Done |
| **RAG Pipeline** | Retrieval + Generation | âœ… Done |
| **Query API** | `/api/query` endpoint | âœ… Done |

### Week 3: Multi-Agent Workflow âœ…
| Component | Technology | Status |
|-----------|------------|--------|
| **Section-Aware Parser** | `SectionAwarePDFParser` | âœ… Done |
| **Canonical Section Taxonomy** | 13 normalized section types | âœ… Done |
| **Intent Classifier** | Rule-based, priority-ordered | âœ… Done |
| **Section-Filtered Retrieval** | Qdrant metadata filters | âœ… Done |
| **HITL Gate** | Human-in-the-loop controls | âœ… Done |
| **Verbosity Control** | Brief/concise summary mode | âœ… Done |
| **Streamlit Frontend** | Temporary demo UI | âœ… Done |
| **3-Agent Workflow** | Query â†’ Retrieval â†’ Analysis | âœ… Done |

### Week 4: Guardrails AI âœ…
| Component | Technology | Status |
|-----------|------------|--------|
| **RAIL Schema** | Guardrails AI RAIL format | âœ… Done |
| **Pydantic Validation** | `ValidatedAnswer` model | âœ… Done |
| **Citation Grounding** | Rule-based verification | âœ… Done |
| **Hallucination Detection** | Heuristic-based checks | âœ… Done |
| **Auto-Retry** | Schema validation retry (max 1) | âœ… Done |
| **HITL Escalation** | Guardrails â†’ HITL pipeline | âœ… Done |

### Week 5: BM42 Hybrid Search âœ…
| Component | Technology | Status |
|-----------|------------|--------|
| **Sparse Embeddings** | BM42 via `fastembed` | âœ… Done |
| **Hybrid Collection** | Qdrant dense + sparse | âœ… Done |
| **RRF Fusion** | Reciprocal Rank Fusion (k=60) | âœ… Done |
| **Weight Config** | Dense: 0.5, Sparse: 0.5 | âœ… Done |

### Week 6: Current State âœ…
**Fully Operational Production-Grade Hybrid RAG System**
- âœ… All core features implemented
- ğŸ”€ **BM42 Hybrid Search active** (dense + sparse)
- ğŸ›¡ï¸ Guardrails AI validation active
- ğŸ“Š Multi-agent workflow operational
- ğŸ” Section-aware retrieval working
- ğŸ’¬ Streamlit demo UI available

## ï¿½ğŸ—ï¸ Architecture

### Multi-Agent Workflow with Guardrails
```
User Question
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Query Orchestrator    â”‚  â†’ Intent Classification
â”‚  Agent                 â”‚  â†’ Section Targeting
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Evidence Retrieval    â”‚  â†’ Metadata-Filtered Search
â”‚  Agent                 â”‚  â†’ Qdrant Vector Query
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  HITL Gate             â”‚  â†’ Confidence Check
â”‚  (Deterministic)       â”‚  â†’ Low Evidence â†’ BLOCK
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Analysis & Synthesis  â”‚  â†’ LLM Reasoning
â”‚  Agent                 â”‚  â†’ Cited Answer
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Guardrails AI         â”‚  â†’ Schema Validation
â”‚  Validation Layer      â”‚  â†’ Citation Grounding
â”‚                        â”‚  â†’ Hallucination Detection
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â€¢ If Valid â†’ Stop Event (Answer)
â€¢ If Invalid â†’ HITL Event (Review Required)
```

### Intent Classification System
| Intent | Allowed Sections | Priority |
|--------|------------------|----------|
| `citation` | References | 100 |
| `limitations` | Discussion, Limitations | 90 |
| `future_work` | Future Work | 85 |
| `research_gaps` | Discussion, Limitations, Future Work | 80 |
| `methodology` | Methods | 70 |
| `experiments` | Experiments, Results | 60 |
| `results` | Results | 50 |
| `comparison` | Results, Experiments | 40 |
| `summary` | Abstract, Introduction | 20 |
| `general` | Abstract, Introduction, Methods, Results | 10 |

### Canonical Section Taxonomy
Only these 13 section labels are stored in the vector database:
```
Abstract, Introduction, Related Work, Methods, Experiments,
Results, Discussion, Limitations, Future Work, Conclusion,
References, Appendix, Unknown
```

### HITL Gate Trigger Conditions
Human review is required if ANY of:
- `retrieved_chunks_count < 2`
- `intent_confidence < 0.6`
- `paper_coverage == 0`

> **Note:** Hybrid retrieval scores are rank-based (RRF) rather than absolute similarity values; confidence is computed using evidence coverage and intent reliability instead of raw similarity thresholds.

## ğŸ› ï¸ Tech Stack

| Layer | Technology | Purpose |
|-------|------------|---------|
| **Framework** | LlamaIndex | RAG orchestration |
| **LLM** | Groq (openai/gpt-oss-120b) | Response generation |
| **Dense Embeddings** | BAAI/bge-base-en-v1.5 | Semantic understanding (768-dim) |
| **Sparse Embeddings** | BM42 via `fastembed` | Keyword matching |
| **Hybrid Search** | RRF Fusion | Dense + Sparse combination |
| **Vector DB** | Qdrant | Hybrid vectors with filters |
| **PDF Reader** | LlamaIndex + PyMuPDF | Document ingestion |
| **API** | FastAPI | REST endpoints |
| **Frontend** | Streamlit (temporary) | Demo UI |
| **Workflow** | LlamaIndex Workflow | Event-driven agents |

## ğŸ“ Project Structure

```
research-paper-intelligence-system/
â”œâ”€â”€ corpus/                             # Research papers (PDFs)
â”‚   â”œâ”€â”€ paper1.pdf
â”‚   â””â”€â”€ paper2.pdf
â”‚
â”œâ”€â”€ backend/                            # FastAPI backend
â”‚   â””â”€â”€ app/
â”‚       â”œâ”€â”€ api/
â”‚       â”‚   â””â”€â”€ routes/
â”‚       â”‚       â”œâ”€â”€ search.py           # Vector search endpoints
â”‚       â”‚       â”œâ”€â”€ query.py            # Query endpoints
â”‚       â”‚       â””â”€â”€ workflow_query.py   # Workflow-based query
â”‚       â”‚
â”‚       â”œâ”€â”€ agents/                     # Multi-agent system
â”‚       â”‚   â”œâ”€â”€ query_orchestrator.py   # Agent 1: Intent classification
â”‚       â”‚   â”œâ”€â”€ evidence_retrieval.py   # Agent 2: Vector retrieval
â”‚       â”‚   â””â”€â”€ analysis_synthesis.py   # Agent 3: LLM synthesis
â”‚       â”‚
â”‚       â”œâ”€â”€ db/
â”‚       â”‚   â””â”€â”€ qdrant_client.py        # Qdrant with metadata filters
â”‚       â”‚
â”‚       â”œâ”€â”€ guardrails/                 # Guardrails AI schemas
â”‚       â”‚   â””â”€â”€ answer_schema.rail      # RAIL validation schema
â”‚       â”‚
â”‚       â”œâ”€â”€ models/                     # Data models
â”‚       â”‚   â”œâ”€â”€ paper.py                # Paper metadata
â”‚       â”‚   â”œâ”€â”€ chunk.py                # Chunk + SearchResult
â”‚       â”‚   â”œâ”€â”€ query.py                # Query request/response
â”‚       â”‚   â””â”€â”€ events.py               # Workflow events (5 events)
â”‚       â”‚
â”‚       â”œâ”€â”€ services/                   # Core services
â”‚       â”‚   â”œâ”€â”€ pdf_parser.py           # Section-aware PDF parser
â”‚       â”‚   â”œâ”€â”€ chunking.py             # Canonical section chunking
â”‚       â”‚   â”œâ”€â”€ embeddings.py           # HuggingFace embeddings
â”‚       â”‚   â”œâ”€â”€ llm_service.py          # Groq LLM integration
â”‚       â”‚   â”œâ”€â”€ intent_classifier.py    # Rule-based intent detection
â”‚       â”‚   â”œâ”€â”€ hitl_gate.py            # Human-in-the-loop controls
â”‚       â”‚   â”œâ”€â”€ guardrails_service.py   # Guardrails AI validation
â”‚       â”‚   â”œâ”€â”€ memory.py               # Memory service
â”‚       â”‚   â””â”€â”€ query_engine.py         # Query engine
â”‚       â”‚
â”‚       â”œâ”€â”€ workflows/
â”‚       â”‚   â””â”€â”€ research_workflow.py    # LlamaIndex Workflow
â”‚       â”‚
â”‚       â”œâ”€â”€ config.py                   # Settings & env vars
â”‚       â””â”€â”€ main.py                     # FastAPI app
â”‚
â”œâ”€â”€ frontend/                           # Streamlit UI (temporary)
â”‚   â””â”€â”€ app.py                          # Demo UI
â”‚
â”œâ”€â”€ build_corpus.py                     # Ingestion pipeline
â”œâ”€â”€ interactive_query.py                # CLI Q&A interface
â”œâ”€â”€ docker-compose.yml                  # Qdrant container
â”œâ”€â”€ requirements.txt                    # Python dependencies
â”œâ”€â”€ .env                                # Environment variables
â””â”€â”€ README.md
```

## ğŸš€ Quick Start

### 1. Prerequisites
- Python 3.10+
- Docker (for Qdrant)
- Groq API key (free at https://console.groq.com)

### 2. Setup

```bash
# Clone and navigate
cd research-paper-intelligence-system

# Create virtual environment
python -m venv venv_clean
.\venv_clean\Scripts\activate  # Windows
# source venv_clean/bin/activate  # Linux/Mac

# Install dependencies
pip install -r requirements.txt
```

### 3. Environment Variables

Create `.env` file:
```env
GROQ_API_KEY=your_groq_api_key_here
```

### 4. Start Qdrant

```bash
docker-compose up -d
```

### 5. Add PDFs & Build Corpus

```bash
# Place PDFs in corpus/ folder
# Then build the vector database
python build_corpus.py
```

### 6. Run the System

**Option A: Interactive CLI**
```bash
python interactive_query.py
```

**Option B: FastAPI + Streamlit**
```bash
# Terminal 1: Start backend
cd backend
uvicorn app.main:app --reload

# Terminal 2: Start frontend
streamlit run frontend/app.py
```

Visit:
- API Docs: http://localhost:8000/docs
- Streamlit UI: http://localhost:8501

## ğŸ’¡ Example Queries

| Query | Intent | Sections Searched |
|-------|--------|-------------------|
| "What is LoRA?" | `summary` | Abstract, Introduction |
| "How does QLoRA work?" | `methodology` | Methods |
| "What are the limitations?" | `limitations` | Discussion, Limitations |
| "Compare LoRA and full fine-tuning" | `comparison` | Results, Experiments |
| "Give a brief summary" | `summary` (brief mode) | Abstract, Introduction |

## âš™ï¸ Configuration

Edit `backend/app/config.py`:

```python
# Dense Embedding Model
embedding_model: str = "BAAI/bge-base-en-v1.5"
embedding_dim: int = 768

# BM42 Sparse Embeddings (Hybrid Search)
sparse_embedding_model: str = "Qdrant/bm42-all-minilm-l6-v2-attentions"
enable_hybrid_search: bool = True

# RRF Fusion Parameters
rrf_k: int = 60  # Reciprocal Rank Fusion constant
dense_weight: float = 0.5
sparse_weight: float = 0.5

# Chunking
chunk_size: int = 1000
chunk_overlap: int = 200

# Qdrant
qdrant_host: str = "localhost"
qdrant_port: int = 6333
qdrant_collection_name: str = "research_papers_hybrid"

# LLM
llm_model: str = "openai/gpt-oss-120b"
```

## ğŸ”¬ Key Features

### Section-Aware Chunking
- Detects real section headers (Abstract, Methods, Results, etc.)
- Normalizes to 13 canonical section names
- Rejects noise (tables, figures, OCR artifacts)

### Intent-Based Retrieval
- Rule-based intent classifier (no ML/LLM)
- Priority-ordered conflict resolution
- Metadata-filtered vector search

### Human-in-the-Loop Controls
- Blocks low-confidence answers
- Returns structured review requests
- Deterministic trigger conditions

### Verbosity Control
- Detects "brief/short/small" hints
- Produces concise bullet-point answers
- No LLM reasoning for verbosity

### Guardrails AI Validation
- **Pydantic Schema Enforcement**: Strict JSON output with `ValidatedAnswer` model
- **Citation Grounding**: Verifies all citations exist in retrieved chunks
- **Hallucination Detection**: Heuristic-based pattern matching
- **Auto-Retry**: Automatically re-asks LLM once if validation fails
- **HITL Escalation**: Triggers human review when quality is insufficient

## ğŸ—ºï¸ Roadmap

- [x] **Week 1**: PDF â†’ Chunks â†’ Embeddings â†’ Qdrant
- [x] **Week 2**: RAG Query Engine with LlamaIndex + Groq LLM
- [x] **Week 3**: Multi-Agent Workflow + HITL + Section Filtering
- [x] **Week 4**: Guardrails AI + Schema Validation
- [x] **Week 5**: BM42 Hybrid Search (Dense + Sparse + RRF Fusion)
- [x] **Week 6**: Production-Grade Hybrid RAG System (Current)
- [ ] **Week 7**: Cloud Deployment + Monitoring

---

## ğŸ§ª How to Evaluate This Project

### Step 1: Environment Setup
```bash
# 1. Clone the repository
git clone https://github.com/Sayandip05/research-paper-intelligence-system.git
cd research-paper-intelligence-system

# 2. Create virtual environment
python -m venv venv_clean
.\venv_clean\Scripts\activate  # Windows
# source venv_clean/bin/activate  # Linux/Mac

# 3. Install dependencies
pip install -r requirements.txt

# 4. Create .env file with your Groq API key
echo "GROQ_API_KEY=your_groq_api_key_here" > .env
```

### Step 2: Start Infrastructure
```bash
# Start Qdrant vector database
docker-compose up -d

# Verify Qdrant is running
curl http://localhost:6333/collections
```

### Step 3: Build Corpus (Index PDFs)
```bash
# Place your research paper PDFs in corpus/ folder
# Then run the indexing pipeline
python build_corpus.py
```

**Expected Output:**
```
ğŸ“š Found 2 PDF files
ğŸ”§ Initializing services...
âœ… Sparse embeddings loaded! (BM42)
ğŸ“„ Processing 1/2: lora.pdf
   âœ“ Created 45 chunks
   âœ“ Generated 45 dense embeddings
   âœ“ Generated 45 sparse embeddings
âœ… HYBRID CORPUS BUILD COMPLETE!
```

### Step 4: Start the System
```bash
# Terminal 1: Start FastAPI backend
cd backend
uvicorn app.main:app --reload --port 8000

# Terminal 2: Start Streamlit frontend
streamlit run frontend/app.py --server.port 8501
```

### Step 5: Test API Endpoints

#### Health Check
```bash
curl http://localhost:8000/health
```
**Expected:**
```json
{"status": "healthy", "agents": 3, "workflow": "LlamaIndex"}
```

#### Corpus Statistics
```bash
curl http://localhost:8000/api/corpus/stats
```
**Expected:**
```json
{
  "total_chunks": 88,
  "collection": "research_papers_hybrid",
  "hybrid_enabled": true,
  "dense_model": "BAAI/bge-base-en-v1.5",
  "sparse_model": "Qdrant/bm42-all-minilm-l6-v2-attentions"
}
```

#### Hybrid Search
```bash
curl -X POST http://localhost:8000/api/search/hybrid \
  -H "Content-Type: application/json" \
  -d '{"query": "What is LoRA rank?", "top_k": 3}'
```
**Expected:**
```json
{
  "query": "What is LoRA rank?",
  "mode": "hybrid",
  "total_found": 3,
  "paper_coverage": 1,
  "results": [...]
}
```

#### Intelligent Query (with LLM)
```bash
curl -X POST http://localhost:8000/api/query \
  -H "Content-Type: application/json" \
  -d '{"question": "What are the limitations of LoRA?", "similarity_top_k": 5}'
```
**Expected:**
```json
{
  "question": "What are the limitations of LoRA?",
  "answer": "LoRA has several limitations...",
  "sources": [...],
  "num_sources": 5
}
```

#### PDF Upload (Auto-Processing)
```bash
curl -X POST http://localhost:8000/api/upload \
  -F "file=@path/to/paper.pdf"
```
**Expected:**
```json
{
  "filename": "paper.pdf",
  "status": "processing",
  "message": "PDF uploaded and processing started..."
}
```

### Step 6: Interactive CLI Testing
```bash
python interactive_query.py
```
**Test Questions:**
1. "What is LoRA?" â†’ Should detect `summary` intent
2. "What are the limitations?" â†’ Should detect `limitations` intent
3. "How does the training work?" â†’ Should detect `methodology` intent
4. "Give a brief summary" â†’ Should produce concise output

### Step 7: Streamlit UI Testing
Visit: http://localhost:8501

**Test Flow:**
1. Upload a PDF via sidebar â†’ Should auto-process
2. Toggle "Hybrid Search" mode
3. Ask: "What is the main contribution?"
4. Verify sources are displayed with sections

---

## ğŸ“Š API Endpoints Reference

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/health` | GET | System health check |
| `/api/corpus/stats` | GET | Corpus statistics with hybrid info |
| `/api/search` | POST | Dense-only vector search |
| `/api/search/hybrid` | POST | Hybrid search (Dense + BM42 + RRF) |
| `/api/query` | POST | Full RAG query with LLM synthesis |
| `/api/query/simple` | POST | Simplified query endpoint |
| `/api/query/health` | GET | Query engine health |
| `/api/query/examples` | GET | Example queries by category |
| `/api/upload` | POST | Upload PDF with auto-processing |
| `/api/upload/status/{filename}` | GET | Check PDF processing status |
| `/api/upload/list` | GET | List PDFs in corpus |

---

## âœ… Evaluation Checklist

| Feature | How to Test | Expected Result |
|---------|-------------|-----------------|
| **PDF Parsing** | `build_corpus.py` | Chunks created with section labels |
| **Hybrid Embeddings** | Check corpus stats | `hybrid_enabled: true` |
| **RRF Fusion** | Hybrid search query | `mode: hybrid` in response |
| **Intent Classification** | Ask methodology question | Returns Methods section chunks |
| **Section Filtering** | Query with section filter | Only specified sections returned |
| **HITL Gate** | Low-confidence query | Returns `human_review_required` |
| **Guardrails** | Complex query | Validated JSON with citations |
| **Auto Upload** | Upload via API | Background processing + status |
| **Streamlit UI** | Visit :8501 | Working Q&A interface |

---

## ğŸ” Key Differentiators

1. **Hybrid Search (BM42 + Dense)**: Combines semantic understanding with keyword matching using Reciprocal Rank Fusion
2. **Section-Aware Retrieval**: Intent-based filtering targets specific paper sections
3. **Production HITL**: Deterministic quality gates without ML dependencies
4. **Guardrails AI**: Schema validation with citation grounding
5. **Auto PDF Processing**: Upload API with background indexing

---

## ğŸ“ License

MIT License

---

Built with â¤ï¸ using LlamaIndex, Qdrant, Groq, and Streamlit

